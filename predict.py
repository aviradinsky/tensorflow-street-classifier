# %%

from matplotlib import pyplot as plt
from tensorflow import keras

from PIL import Image
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

import tensorflow.keras.preprocessing.image as tfim
import tensorflow_datasets as tfds
import tensorflow as tf
import numpy as np
import cv2 as cv
import random
import time
import sys
import os

import scale_and_slide as sas
import selective_search as ss
import params

# %%

# classes = {
#     0:   'bike',
#     1:   'motorcycle',
#     2:   'bus',
#     3:   'truck',
#     4:   'car',
#     5:   'train',
#     6:   'person',
#     7:   'traffic light',
#     8:   'stop sign',
#     9:   'fire hydrant',
#     10: 'background'
# }
classes = params.chosen_labels
classes.append("background")
classes.sort()

# %%

def display_image(image):
    plt.imshow(image)
    plt.axis('off')
    plt.show()
# %%

def load_model(filepath, show_summary=True):
    """Get the model stored at the given filepath

    Args:
        filepath (str): path to the model stored.
        show_summary (bool, optional): display summary of the model's
                                       architecture. Defaults to True.

    Returns:
        tf.keras.Model: the model
    """
    # load the model
    model = tf.keras.models.load_model(filepath)
    if show_summary:
        # Check its architecture
        model.summary()
    return model

# %%

def get_sas_crops(image: Image.Image, size: tuple, stride: int):
    """Get the crops and accompanying bounding boxes of a given image
    generated by pyramid scaling and sliding windows.

    Args:
        image (Image.Image): image to crop.
        size (tuple): target crop size.
        stride (int): sliding window stride.

    Returns:
        list, list: a list of numpy arrays of images and a list of
                    the corresponding bounding boxes of the crops on 
                    the original image.
    """
    crops_pairs = sas.get_image_chunks(image, size, stride)
    zipped = list(zip(*crops_pairs))
    crops = list(zipped[0])
    bboxes = list(zipped[1])
    return crops, bboxes

# %%

def get_ss_crops(image: Image.Image):
    """Get the crops and accompanying bounding boxes of a given image
    generated by cv2's selective search implementation.

    Args:
        image (Image.Image): Image to crop.

    Returns:
        list, list: a list of numpy arrays of images and a list of
                    the corresponding bounding boxes of the crops on 
                    the original image.
    """
    crops_pairs = ss.selective_search(np.array(image))
    zipped = list(zip(*crops_pairs))
    crops = list(zipped[0])
    bboxes = list(zipped[1])
    return crops, bboxes

# %%

def predict(model_path: str, test_image: Image.Image, 
            crops: list, bboxes: list):
    """Display bounding boxes and labels detected by the given model 
    on the given image.

    Args:
        model_path (str): path to model. If there is a model saved at
                          the path, it will be loaded. Otherwise, the
                          model module will be loaded, resulting in a
                          model being trained and saved at this path.
        image (Image.Image): image for the model to predict.
        crop_dims (tuple): dimensions of sliding window crops.
        stride (int): sliding window stride.
    """
    if not os.path.exists(model_path):
        import model_v2

    model = load_model(model_path)

    # find and resize images to model input size
    in_tensor = keras.backend.int_shape(model.layers[0].input)
    input_size = (in_tensor[1], in_tensor[2], in_tensor[3])
   
    for i, crop in enumerate(crops):
        im = Image.fromarray(np.uint8(crop)).convert('RGB')
        im = im.resize((input_size[0], input_size[1]))
        crops[i] = np.array(im)

    # run predict on each crop
    print ('len crops: ' + str(len(crops)))
    tally = 0
    cutoff = .8
    # keep track of crops that meet cutoff
    top_preds = []

    # convert crops to tensors
    tensors = [tf.convert_to_tensor(x) for x in crops]
    # turn into batch
    stacked = tf.stack(tensors)

    start = time.time()
    predictions = model.predict(stacked)
    end = time.time()
    elapsed = round(end - start, 5)
    print(f'total predict time: {elapsed} seconds')

    for i in range(len(predictions)):
        pred = predictions[i]
        score = tf.nn.softmax(pred)
        im_class = classes[np.argmax(score)]
        if tf.reduce_max(score).numpy() >= cutoff:
            top_preds.append((crops[i], bboxes[i], im_class))
            tally += 1

    print(f'total crops with prob > {cutoff}: ', tally)

    # randomly display the best crops with bboxes and labels
    random.shuffle(top_preds)
    # draw bounding boxes on original image
    img_array = np.array(test_image.copy())
    i = 0
    
    background_count = 0

    # each crop_tupl has three elements: (image, bbox, class_label)
    for crop_tupl in top_preds:
        # create color of bounding box (at random)
        colors = []
        for _ in range(3):
            colors.append(random.randint(0,255))
        if crop_tupl[2] == 'background':
            background_count += 1
            continue
            # sys.exit()
        if i < 20:
        # if crop_tupl[2] == 'person':
            # bboxes are in order of (left, top, right, bottom)
            top_left = (crop_tupl[1][0], crop_tupl[1][1])
            bottom_right = (crop_tupl[1][2], crop_tupl[1][3])
            img_array = cv.rectangle(img_array, pt1=top_left, 
                                    pt2=bottom_right, color=tuple(colors),
                                    thickness=3)
            txt_pos = (top_left[0], bottom_right[1] + 20)
            cv.putText(img_array, crop_tupl[2], txt_pos,
                       cv.FONT_HERSHEY_DUPLEX, 1,(0,0,0),2)
            i += 1

    print(f'number of background crops left out: {background_count}')
    img = Image.fromarray(img_array)
    display_image(np.array(img))

# %%

def predict_sas(model_path: str, image: Image.Image, 
            crop_dims: tuple, stride: int):
    """Display bounding boxes and labels detected by the given model 
    on the given image. The bounding boxes are generated through
    pyramid scaling and sliding windows.

    Args:
        model_path (str): path to model. If there is a model saved at
                          the path, it will be loaded. Otherwise, the
                          model module will be loaded, resulting in a
                          model being trained and saved at this path.
        image (Image.Image): image for the model to predict.
        crop_dims (tuple): dimensions of sliding window crops.
        stride (int): sliding window stride.
    """
    # resize image to width of 750 px, and proportional height
    factor = 750 / image.width
    size = (int(image.width * factor), int(image.height * factor))
    test_image = image.resize(size)
    display_image(test_image)
    # get crops and bboxes
    crops, bboxes = get_sas_crops(test_image, crop_dims, stride)
    # run predict
    predict(model_path, image, crops, bboxes)

# %%

def predict_ss(model_path: str, image: Image.Image):
    """Display bounding boxes and labels detected by the given model 
    on the given image. The bounding boxes are generated by the cv2
    selective search implementation.

    Args:
        model_path (str): path to model. If there is a model saved at
                          the path, it will be loaded. Otherwise, the
                          model module will be loaded, resulting in a
                          model being trained and saved at this path.
        image (Image.Image): image to feed into model.
    """
    # get crops and bboxes
    crops, bboxes = get_ss_crops(image)
    # run predict
    predict(model_path, image, crops, bboxes)
    
# %%

def test():
    start = time.time()
    # # get test image
    # img_path = 'predict_img.jpg'
    # test_image = Image.open(img_path)
    x=0
    images=[]
    for data in tfds.as_numpy(tfds.load('coco').get('test2015')):
        #print(data)
        if(x>5):
            break

        image = Image.fromarray(data['image']) 
        #image.show()
        #print(data['image/filename'].decode("utf-8") )
        images.append(image)
        x+=1
    test_image =images[1]

    model_path = params.model_dir
    crop_dims = (65,100)
    stride = 40

    # predict_sas(model_path, test_image, crop_dims, stride)
    print('******************\nEND SAS PREDICT\n******************')
    predict_ss(model_path, test_image)
    print('******************\nEND SS PREDICT\n******************')
    end = time.time()
    elapsed = end - start
    print(f'total predict time was: {elapsed}')
    display_image(test_image)

# %%

if __name__ == '__main__':
    test()

# %%
